{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:1000 px\">\n",
    "\n",
    "<div style=\"float:right; width:98 px; height:98px;\">\n",
    "<img src=\"https://raw.githubusercontent.com/Unidata/MetPy/master/src/metpy/plots/_static/unidata_150x150.png\" alt=\"Unidata Logo\" style=\"height: 98px;\">\n",
    "</div>\n",
    "\n",
    "<h1>Using Siphon and MetPy to access and manipulate data<h1>\n",
    "    <h3>AMS 2022 Short Course: MetPy for Quantitative Analysis of Meteorological Data</h3>\n",
    "\n",
    "<div style=\"clear:both\"></div>\n",
    "</div>\n",
    "\n",
    "<hr style=\"height:2px;\">\n",
    "\n",
    "### Tasks\n",
    "1. <a href=\"#tdscatalog\">Working with the TDS Catalog</a>\n",
    "1. <a href=\"#datastruct\">Working with xarray Data Structures</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"background\"></a>\n",
    "## Background\n",
    "Atmospheric data are collected by numerous institutions in a variety of data formats and stored in disparate places. Accessing and distributing these datasets are complicated activities, but are made simpler with the use of the THREDDS Data Server (TDS). In this lesson, you will learn more about data access with the TDS and how to use data in Python.\n",
    "\n",
    "### THREDDS Data Server (TDS)\n",
    "THREDDS is middleware to bridge the gap between data providers and data users. Data on the TDS are organized into catalogs that data users can browse and use to request data. While anyone can host their own TDS, Unidata hosts a publicly accessible TDS at [thredds.ucar.edu](https://thredds.ucar.edu/).\n",
    "\n",
    "### Siphon\n",
    "A web browser is one way to interact with a TDS, but we can also pull data from a TDS into Python projects using the Siphon Python package. Siphon doesn't require downloading data locally, saving time and storage space. Once pulled into Python, we can use packages like MetPy and Cartopy to visualize and analyze the data.\n",
    "\n",
    "<center><img src=\"https://elearning.unidata.ucar.edu/metpy/AMS2022/TDSecosystem.png\" width=\"300\"/><br>\n",
    "<i>The TDS - Siphon - Python ecosystem</i></center>\n",
    "<br><br>\n",
    "Siphon accomplishes this through a <b>TDS catalog</b> object created from an xml catalog document served by the TDS. This is a virtual catalog of items that are available on the TDS that we can then access remotely (or download locally if needed).\n",
    "\n",
    "`cat = TDSCatalog('https://thredds.ucar.edu/.../catalog.xml') `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"tdscatalog\"></a>\n",
    "## Working with Siphon\n",
    "\n",
    "### The TDSCatalog\n",
    "\n",
    "We can view a THREDDS Data Server (TDS) Catalog in a browser as well as in Python. For this activity, we'll start by examining Unidata's TDS catalog in our browser. <a href=\"https://thredds.ucar.edu\" target=\"blank\">https://thredds.ucar.edu</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>: TDS in the browser\n",
    "    \n",
    "\n",
    "Open this TDS link in a new tab in your browser: <a href=\"https://thredds.ucar.edu\" target=\"blank\">https://thredds.ucar.edu</a>\n",
    "    \n",
    "Locate the following catalog:\n",
    "    \n",
    " <ul>\n",
    "     <li>Source: High Resolution Rapid Refresh (HRRR), Analysis</li> \n",
    "     <li>Resolution: 2.5 km </li>\n",
    "     <li>Collection: latest</li>\n",
    "</ul>\n",
    "    \n",
    "Then create a variable called <code>url</code> with a value set to the URL to the dataset as a string.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TDSCatalog object requires an xml document as input, so we now change the extension from html to xml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the URL above to be an xml document using Python's built-in replace module\n",
    "url_xml = url.replace(\".html\", \".xml\")\n",
    "print(url_xml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the catalog located, it's time to create and examine the TDSCatalog object. First we import the object from Siphon, then we input the url to the catalog of data we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the TDSCatalog class from Siphon for obtaining our data \n",
    "from siphon.catalog import TDSCatalog\n",
    "\n",
    "# Create the TDS Catalog object, satcat\n",
    "cat = TDSCatalog(url_xml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a catalog of the grib2 files we found in the browser. The names of each file are stored in the `datasets` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all filenames associated with the catalog\n",
    "print(cat.datasets)\n",
    "\n",
    "# Total number of files\n",
    "print('Total files: ' + str(len(cat.datasets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example there is only one file referenced within this catalog. We can inspect what data access pathways the TDS and Siphon provide for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = cat.datasets[0]\n",
    "ds.access_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NetCDF Subset Service (NCSS)\n",
    "\n",
    "Our focus for this workshop will be accessing the TDS NetCDF Subset Service (NCSS) via Siphon, which will enable us to generate a NetCDF file with our relevant data variables, spatial subset, and more, regardless of the specific data format behind the scences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://thredds.ucar.edu/thredds/catalog/grib/NCEP/GFS/Global_0p5deg/catalog.xml'\n",
    "cat = TDSCatalog(url)\n",
    "cat.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncss = cat.datasets['Best GFS Half Degree Forecast Time Series'].subset()\n",
    "# ncss.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "query = ncss.query()\n",
    "query.add_lonlat()\n",
    "query.lonlat_box(west=-130, east=-50, south=10, north=60)\n",
    "query.time(datetime.utcnow())\n",
    "query.variables('Temperature_isobaric',\n",
    "                'Geopotential_height_isobaric',\n",
    "                'u-component_of_wind_isobaric',\n",
    "                'v-component_of_wind_isobaric')\n",
    "query.accept('netcdf4')\n",
    "\n",
    "nc = ncss.get_data(query)\n",
    "nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>: Explore NCSS in the browser\n",
    "    \n",
    "\n",
    "Pick up where you left off from the previous exercise! The URL for the catalog we identified before is https://thredds.ucar.edu/thredds/catalog/grib/NCEP/HRRR/CONUS_2p5km_ANA/latest.html if you need it again.\n",
    "    \n",
    "Inspect the actual dataset, in this case the `.grib2` file present. On this page, you will see a visual representation of the access URLs we had Siphon display for us above.\n",
    "\n",
    "* Using these URLs, access the data via **NetcdfSubset** in your browser\n",
    "* Explore the available variables and select one or more you're interested in\n",
    "    * Share the name of one of these variables in the chat\n",
    "* Change the Output Format to `netcdf4`\n",
    "* **Optional:** **submit** a request to download your custom NetCDF file from the server\n",
    "    \n",
    "While here, be sure to notice the variety of vertical coordinates present in the data.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"datastruct\"></a>\n",
    "## Working with xarray\n",
    "\n",
    "### xarray Primer\n",
    "\n",
    "Now we have an xarray **Dataset** that we can work with. This is a framework used for organizing multidimensional datasets, such as NetCDF and GRIB. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-warning\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">More Info</p>\n",
    "    You may see the CF (Climate and Forecasting) metadata conventions in many popular atmospheric datasets. These conventions provide standardized variable names and units and recommendations on metadata such as projection information and coordinate information. You can read more about CF conventions here: <a href=\"cfconventions.org\" target=\"blank\">https://cfconventions.org/</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from xarray.backends import NetCDF4DataStore\n",
    "\n",
    "ds = xr.open_dataset(NetCDF4DataStore(nc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![xarray diagram](https://github.com/pydata/xarray/raw/main/doc/_static/dataset-diagram.png \"xarray model diagram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xarray has an HTML-formatted interactive summary tool for examing datasets. Simply execute the variable name to create the summary. This is a tool we will use often to examine our data throughout this course.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview xarray DataSet in an HTML-formatted preview\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preview, we see an interactive summary of the dimensions, coordinates, variables, attributes for the DataSet. Each variable is stored as an xarray [DataArray](https://docs.xarray.dev/en/stable/user-guide/data-structures.html#dataarray). DataArrays carry metadata such as units and projection as well as a numpy-like array of values that MetPy can leverage for calculations and plotting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['Temperature_isobaric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ds.Temperature_isobaric\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `temp` is now an xarray DataArray that we can interact with. Notice how there are 4 dimensions in this DataArray:\n",
    "- `time` (length 1)\n",
    "- `isobaric1` (length 41)\n",
    "- `lon` (length 101)\n",
    "- `lat` (length 161)\n",
    "\n",
    "However, for plotting (and many analyses), we need a 2D array. \n",
    "\n",
    "First, we can remove the time dimension using the `squeeze()` method to eliminate any dimensions of length 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.squeeze()\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xarray with MetPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xarray provides many pandas-style <a href=\"https://xarray.pydata.org/en/stable/user-guide/indexing.html\" target=\"blank\">indexing methods</a> for selecting data using descriptive labels or coordinate locations. Using MetPy, we can make these smartly unit-aware and select e.g. the 925 hPa level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL MetPy xarray helpers become\n",
    "# available with ANY MetPy import\n",
    "from metpy.units import units\n",
    "\n",
    "# select vertical level equal to 925 hPa\n",
    "temp_925 = temp.metpy.sel(vertical=925 * units.hPa)\n",
    "temp_925"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, MetPy can identify your relevant coordinates _regardless of their specific names_. This is useful for meteorological data, where data variables might rely on differently named coordinates present within the same dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_925.metpy.vertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_925.isobaric1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>: Get 1000 hPa geopotential height\n",
    "<br><br>    \n",
    "Create a 2D array of geopotential height at the 1000 hPa (10000 Pa) level.\n",
    "    \n",
    "<ol>\n",
    "     <li>From the <code>ds</code> DataSet, pull the <code>Geopotential_height_isobaric</code> DataArray</li> \n",
    "     <li><code>squeeze()</code> out any dimensions of length 1</li>\n",
    "     <li><code>.sel()</code> the 1000 hPa vertical level</li>\n",
    "     <li>Write the DataArray to a variable named <code>hgt1000</code>\n",
    "     <li>Record the first data value of this 2-dimensional array to share.\n",
    "     <li><b>Optional:</b> Create a simple plot of your result if you're already familiar with Matplotlib.</li>\n",
    "</ol>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get back to our 925 hPa Temperature DataArray. Metpy enables for us a variety of shortcuts to explore the units of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_925.metpy.convert_units('degC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall unit `quantity` objects from the previous notebook. We can create those automatically from the underlying data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_925.metpy.unit_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, by default, these unique `quantity` objects are not already present in our DataArrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_925"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, for some MetPy calculations, we need these to be present _within_ xarray objects. We can do this by _quantifying_ the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_925_quant = temp_925.metpy.quantify()\n",
    "temp_925_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_925_quant.metpy.dequantify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the last important piece of functionality we will explore today is making our data more _geographically aware_ using MetPy. This relies on the powerful [Pyproj](https://pyproj4.github.io/pyproj/stable/) and [Cartopy](https://scitools.org.uk/cartopy/docs/latest/) libraries, as well as standardized metadata in compliance with [CF Conventions](https://cfconventions.org).\n",
    "\n",
    "Using these standardized metadata, we can characterize the data-relevant projection automatically with MetPy's `parse_cf()` xarray method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.metpy.parse_cf().squeeze()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the new `metpy_crs` coordinate! MetPy will look for this coordinate in a variety of its calculations, including spatial calculations and cross-sections. Let's take a look at a calculation made smarter by this,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metpy.calc as mpcalc\n",
    "mpcalc.advection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_850 = ds.Temperature_isobaric.metpy.sel(vertical=850 * units.hPa)\n",
    "u_850 = ds['u-component_of_wind_isobaric'].metpy.sel(vertical=850 * units.hPa)\n",
    "v_850 = ds['v-component_of_wind_isobaric'].metpy.sel(vertical=850 * units.hPa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_adv_850 = mpcalc.advection(temp_850, u=u_850, v=v_850)\n",
    "temp_adv_850"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `metpy_crs` is available after using `parse_cf()`, we can also use a few shortcuts to get us familiar plotting information and more. You might be familiar with creating Cartopy `crs` objects for plotting or transforming data onto maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That sure is annoying to specify correctly for every new dataset or project we tackle. Could we make this easier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See our full [xarray tutorial](https://unidata.github.io/MetPy/latest/tutorials/xarray_tutorial.html) on the documentation for more examples and what to do if your data isn't CF-compliant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>: Calculating advection of a new variable\n",
    "    \n",
    "Recreate the steps we've followed so far to calculate **700 hPa advection of variables of your choosing**.\n",
    "    \n",
    "* Create the appropriate `TDSCatalog` to reach our GFS data.\n",
    "* Query the `Best GFS Half Degree Forecast Time Series` dataset using NCSS as before.\n",
    "* Request our `u` and `v` winds on their isobaric surfaces again.\n",
    "* Find one or more new variables _on the same `isobaric` surface_ (**hint**, look at the variable names with `NCSS.variables`) and add those to our `query`. Something like _specific humidity_ could be interesting!\n",
    "* Use our new `query` to get our NetCDF data from the server.\n",
    "* Open our NetCDF dataset in xarray using the `NetCDFDataStore`, `squeeze` out any extra dimensions, and `parse_cf` the geographic metadata.\n",
    "* Finally, calculate advection of one or more new variables on the **700 hPa isobaric level**.\n",
    "* **Optionally**, plot the resulting calculation.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "url = ''\n",
    "cat = \n",
    "\n",
    "ncss = cat.datasets['Best GFS Half Degree Forecast Time Series'].subset()\n",
    "\n",
    "query = ncss.query()\n",
    "query.lonlat_box(west=-130, east=-50, south=10, north=60)\n",
    "query.time(datetime.utcnow())\n",
    "query.accept('netcdf4')\n",
    "# The rest is up to you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyaos-ams-2022]",
   "language": "python",
   "name": "conda-env-pyaos-ams-2022-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
