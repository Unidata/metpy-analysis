{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div style=\"width:1000 px\">\n",
    "\n",
    "<div style=\"float:right; width:98 px; height:98px;\">\n",
    "<img src=\"https://raw.githubusercontent.com/Unidata/MetPy/master/src/metpy/plots/_static/unidata_150x150.png\" alt=\"Unidata Logo\" style=\"height: 98px;\">\n",
    "</div>\n",
    "\n",
    "<h1>Remote Data Access</h1>\n",
    "    <h3>MetPy for Quantitative Analysis of Meteorological Data</h3>\n",
    "\n",
    "<div style=\"clear:both\"></div>\n",
    "</div>\n",
    "\n",
    "<hr style=\"height:2px;\">\n",
    "\n",
    "### Topics\n",
    "1. <a href=\"#siphon\">Remote Data Access I: Working with Siphon</a>\n",
    "1. <a href=\"#xarray\">Working with xarray</a>\n",
    "1. <a href=\"#ncss\">Remote Data Access II: NetCDF Subset Service (NCSS)</a>\n",
    "1. <a href=\"#cartopy\">Coordinate Reference Systems</a>\n",
    "1. <a href=\"#calc\">Preview: Calculations</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"background\"></a>\n",
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Atmospheric data are collected by numerous institutions in a variety of data formats and stored in disparate places. Accessing and distributing these datasets are complicated activities, but are made simpler with the use of the THREDDS Data Server (TDS). In this lesson, you will learn more about data access with the TDS and how to use data in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"siphon\"></a>\n",
    "## Remote Data Access I: Working with Siphon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<video width=\"600\" src=\"https://elearning.unidata.ucar.edu/metpy/QuantitativeAnalysisILT/SiphonTDS/IntroSiphonTDS.mp4\"  \n",
    "       controls>\n",
    "</video>\n",
    "\n",
    "<a href=\"https://elearning.unidata.ucar.edu/metpy/QuantitativeAnalysisILT/SiphonTDS/IntroSiphonTDS.mp4\" target=\"blank\">Video source</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### The TDSCatalog\n",
    "\n",
    "Let's now practice the demo we saw in the video by requesting the same data from Unidata's THREDDS Data Server, <a href=\"https://thredds.ucar.edu\" target=\"blank\">https://thredds.ucar.edu</a>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = 'https://thredds.ucar.edu/thredds/catalog/satellite/goes/east/products/CloudAndMoistureImagery/CONUS/Channel02/current/catalog.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using string parsing, we can automate replacing the .html extension with a .xml extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the URL above to be an xml document using Python's built-in replace module\n",
    "url_xml = url.replace(\".html\", \".xml\")\n",
    "print(url_xml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the catalog xml document, it's time to create the TDSCatalog object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the TDSCatalog class from Siphon for obtaining our data \n",
    "from siphon.catalog import TDSCatalog\n",
    "\n",
    "# Create the TDS Catalog object, satcat\n",
    "cat = TDSCatalog(url_xml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a <a href=\"https://thredds.ucar.edu/thredds/catalog/satellite/goes/east/products/CloudAndMoistureImagery/CONUS/Channel02/current/catalog.html\" target=\"blank\">catalog of the netCDF files available</a>. The names of each file are stored in the `datasets` property. For this example we'll just look at the first item. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.datasets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the `remote_access()` method to start requesting the data from the latest collection using the default CdmRemote service and returning data in xarray format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = cat.datasets[0].remote_access(use_xarray=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>DISCUSSION</b>: \n",
    "\n",
    "The CdmRemote service creates a netCDF-like object on the TDS that a client can make incremental requests to. \n",
    "\n",
    "1. How does this setup benefit you, the user?\n",
    "2. When does it not make sense to use the CdmRemote service?\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"xarray\"></a>\n",
    "## Working with xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### xarray primer\n",
    "\n",
    "Now we have an xarray **Dataset** that we can work with. This is a framework used for organizing multidimensional datasets, such as NetCDF and GRIB. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![xarray diagram](https://github.com/pydata/xarray/raw/main/doc/_static/dataset-diagram.png \"xarray model diagram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xarray has an HTML-formatted interactive summary tool for examing datasets, as we just saw above. Simply execute the variable name to create the summary. This is a tool we will use often to examine our data throughout this session.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-warning\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">More Info</p>\n",
    "    <i>Multidimensional datasets:</i> <br>For further information about multidimensional data structures, check out the microlearning module on Unidata eLearning: <a href=\"https://elearning.unidata.ucar.edu/mod/scorm/view.php?id=32\" target =\"blank\">Multidimensional Data Structures</a>\n",
    "<br><br>\n",
    "<i>CF Conventions:</i> <br>You may see the CF (Climate and Forecasting) metadata conventions in many popular atmospheric datasets. These conventions provide standardized variable names and units and recommendations on metadata such as projection information and coordinate information. You can read more about CF conventions here: <a href=\"cfconventions.org\" target=\"blank\">https://cfconventions.org/</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview xarray DataSet in an HTML-formatted preview\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preview, we see an interactive summary of the dimensions, coordinates, variables, attributes for the DataSet. Each variable is stored as an xarray [DataArray](https://docs.xarray.dev/en/stable/user-guide/data-structures.html#dataarray). DataArrays carry metadata such as units and projection as well as a numpy-like array of values that MetPy can leverage for calculations and plotting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['Sectorized_CMI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables can be referenced using list notation, as above, or dot notation, as below. Recall that you can use the tab key after the dot to look up available options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmi = ds.Sectorized_CMI\n",
    "cmi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `cmi` DataArray can then be used for plotting, aggregating with other data, quantitative anlayses, among many other tasks. \n",
    "\n",
    "The satellite data we requested contains only one 2D image at a specific time. However, other multidimensional datasets may include many variables, times, vertical coordinates, and other information. Slicing multidimensional data into 2D DataArrays is a common practice for plotting and analyses, so let's request a different dataset and further explore helpful xarray tools. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xarray selection tools\n",
    "\n",
    "Let's start by first requesting a new reanalysis dataset that contains a lot more times and variables, such as the HRRR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>: Request HRRR data from a THREDDS Data Server\n",
    "    \n",
    "Open this TDS link in a new tab in your browser: \n",
    "    \n",
    "Locate the following catalog from Unidata's THREDDS Data Server (<a href=\"https://thredds.ucar.edu\" target=\"blank\">https://thredds.ucar.edu</a>):\n",
    "    \n",
    " <ul>\n",
    "     <li>Source: High Resolution Rapid Refresh (HRRR) Forecast Model</li> \n",
    "     <li>Type: Analysis</li>\n",
    "     <li>Resolution: 2.5 km </li>\n",
    "     <li>Collection: latest</li>\n",
    "</ul>\n",
    "    \n",
    "<ol>\n",
    "    <li>Open the latest available dataset as a variable called <b>hrrr_ds</b></li>\n",
    "    <li>Create a variable called <b>temp</b> that contains the <i>Temperature_isobaric</i> variable as a DataArray</li> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HRRR DataSet has many, many more variables and dimensions than the satellite DataSet. However, most plotting and analysis tools only take inputs with one or two dimensions. To do meaningful work with high-dimensionality data like this, we need to become very familiar with selection tools to reduce dimensionality by taking slices through our data. \n",
    "\n",
    "Notice in the HRRR DataSet, there are many dimensions, but they can be summarized as:\n",
    "- time\n",
    "- x\n",
    "- y\n",
    "- z (height above ground)\n",
    "- z (isobaric)\n",
    "- z (pressure difference layers)\n",
    "\n",
    "Under the hood, MetPy can identify your relevant coordinates _regardless of their specific names_. This is useful for meteorological data, where data variables might rely on differently named coordinates present within the same dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ALL MetPy xarray helpers become\n",
    "# available with ANY MetPy import\n",
    "from metpy.units import units\n",
    "\n",
    "temp.metpy.vertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp.metpy.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xarray provides many pandas-style <a href=\"https://xarray.pydata.org/en/stable/user-guide/indexing.html\" target=\"blank\">indexing methods</a> for selecting data using descriptive labels or coordinate locations. Using MetPy, we can make these smartly unit-aware and select e.g. the 925 hPa level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select vertical level equal to 925 hPa\n",
    "temp_925 = temp.metpy.sel(vertical = 925 * units.hPa)\n",
    "temp_925"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also string selections together to reduce dimensionality of the variables in a single step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# choose a vertical level\n",
    "z = 500 * units.hPa\n",
    "\n",
    "# choose a time\n",
    "t = temp.metpy.time[0]\n",
    "\n",
    "temp_500 = temp.metpy.sel(vertical = z, time = t)\n",
    "temp_500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, use the `method = nearest` parameter in the selection method to choose a time closest to a given `datetime`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-warning\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">More Info</p>\n",
    "    <i>datetime:</i> For further information about datetime objects, review the <a href=\"https://foundations.projectpythia.org/core/datetime/datetime.html\" target=\"blank\">datetime lesson in Project Pythia</a>\n",
    "<br><br>\n",
    "<i>Formatting help:</i> Python strftime cheatsheet: <a href=\"cfconventions.org\" target=\"blank\">https://strftime.org/</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# choose a random time within the time bounds of the dataset\n",
    "t = datetime.strptime('2023-08-14T03:30:00', '%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "# append the method parameter\n",
    "temp_timesel = temp.metpy.sel(vertical = z, time = t, method = 'nearest')\n",
    "temp_timesel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"ncss\"></a>\n",
    "## Remote Data Access II: NetCDF Subset Service (NCSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We previously worked with data on a TDS using the CdmRemote service. In this next section, we will access remote data using the TDS NetCDF Subset Service (NCSS) via Siphon. This enables us to generate a NetCDF file from a custom query for specific data variables, spatial subset, and more, regardless of the data format at the source. This service can be used <a href=\"https://thredds.ucar.edu/thredds/ncss/grid/grib/NCEP/GFS/Global_0p5deg/Best/dataset.html\" target=\"blank\">entirely in the browser</a>, or using Siphon. \n",
    "\n",
    "The transfer of information among your computer, the TDS, and the data source looks like this: \n",
    "<img src='https://elearning.unidata.ucar.edu/metpy/QuantitativeAnalysisILT/NCSS/NCSS_full.gif' width=800/>\n",
    "\n",
    "When using Siphon, this process starts by creating a TDSCatalog object, similar to the previous workflow. The rest of the process looks like this:\n",
    "\n",
    "1. Open a connection from a single catalog dataset for communicating with the NCSS service using the `.subset()` method\n",
    "1. Create a `query` parameter on the NCSS connection object and populate with subset requests\n",
    "1. Request data from the NCSS service with the query parameters\n",
    "1. To optionally work with the data using xarray tools, use the xarray `open_dataset()` method with the `NetCDF4DataStore` backend function (enables reading a netCDF file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TDS Catalog object\n",
    "url = 'https://thredds.ucar.edu/thredds/catalog/grib/NCEP/GFS/Global_0p5deg/catalog.xml'\n",
    "cat = TDSCatalog(url)\n",
    "cat.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open communication to NCSS service\n",
    "ncss = cat.datasets['Best GFS Half Degree Forecast Time Series'].subset()\n",
    "# ncss.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# populate query parameters\n",
    "query = ncss.query()\n",
    "query.add_lonlat()\n",
    "query.lonlat_box(west=-130, east=-50, south=10, north=60)\n",
    "query.time(datetime.utcnow())\n",
    "query.variables('Temperature_isobaric',\n",
    "                'Geopotential_height_isobaric',\n",
    "                'u-component_of_wind_isobaric',\n",
    "                'v-component_of_wind_isobaric')\n",
    "query.accept('netcdf4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit request\n",
    "nc = ncss.get_data(query)\n",
    "nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we open the data as an xarray DataSet object. We can also append the `parse_cf()` method to prepare the data all in a single line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open in xarray\n",
    "import xarray as xr\n",
    "gfs_ds = xr.open_dataset(xr.backends.NetCDF4DataStore(nc))\n",
    "gfs_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pause!**\n",
    "\n",
    "Before we get any further with using these data, however, we're going to take a side-step to talk about these data as they exist on a three-dimensional globe. \n",
    "\n",
    "When it comes to plotting, we often want to plot our data not on a Cartesian grid, but on geographically-referenced axes. Let's explore another important piece of functionality that makes our data more _geographically aware_ using MetPy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"cartopy\"></a>\n",
    "## Coordinate Reference Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<p>A coordinate reference system refers to a generic system for referencing geographic data onto a planar surface. We can have projected coordinate reference systems as well as geographic coordinate reference systems, but this lesson will primarily refer to projected coordinate reference systems, or \"projections\". Cartographers over the years have created several projections or methods to stretch and distort 3D surfaces onto a 2D surface. Projections can preserve attributes like distance, direction, shape, or area, but never all four.</p>\n",
    "\n",
    "<img src='https://elearning.unidata.ucar.edu/metpy/QuantitativeAnalysisILT/projections.png'>\n",
    "\n",
    "<p>If we want to display geographically realistic depictions of our meteorological data, we need to plot our data not on a Cartesian grid (such as those offered by matplotlib functions), but instead on axes that take a projection into account. This is where <code>Cartopy</code> comes in. </p>\n",
    "\n",
    "<p><a href=\"https://scitools.org.uk/cartopy/docs/latest/\" target=\"blank\">Cartopy</a> builds on matplotlib plotting functions to offer projected axes to plot geographic data on. Cartopy offers a variety of <a href=\"https://scitools.org.uk/cartopy/docs/latest/reference/crs.html#list-of-projections\" target=\"blank\">projections</a> as well as geographic reference features that make adding context to maps simple.</p>\n",
    "\n",
    "<p>Creating a figure with geographic axes is very similar to creating any other plot with Matplotlib. First import Cartopy's projection engine <code>ccrs</code> and matplotlib using the standard conventions.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Then create a figure and axes, but include the <code>projection</code> keyword in the <code>add_subplot()</code> method. Here's an example of how to create axes with the Lambert Conformal projection.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection=ccrs.LambertConformal())\n",
    "\n",
    "# add Cartopy's built-in coastlines for reference\n",
    "ax.coastlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p>It's important to know which reference system your data are recorded in so that they can be matched to the correct location on the geographic plot. MetPy provides a function for easily getting that information, provided that the data uses following <a href=\"https://cfconventions.org/\" target=\"blank\">CF conventions</a>, called <code>parse_cf()</code>. Let's try this on the GFS DataSet output from earlier.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import metpy\n",
    "\n",
    "# execute parse_cf function\n",
    "gfs_ds = gfs_ds.metpy.parse_cf()\n",
    "\n",
    "# display the new coordinate\n",
    "gfs_ds.metpy_crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The coordinate reference system in this case uses latitude and longitude. While this is technically not a \"projected\" coordinate reference system, we can simulate this coordinate reference system as a projection using the Plate Carrée projection. The <a href=\"https://pro.arcgis.com/en/pro-app/latest/help/mapping/properties/plate-carree.htm\" target=\"blank\">Plate Carrée projection</a> is commonly used in global model output, as it displays data in equally spaced latitudes and longitudes and preserves direction.</p>\n",
    "\n",
    "<p>Now that we have this information, we can use this to plot any 2D variables from the NCEP analysis DataSet. We will need the following:</p>\n",
    "\n",
    "<ol>\n",
    "    <li>2D data array</li>\n",
    "    <li>the x coordinates corresponding to each cell in the 2D array</li>\n",
    "    <li>the y coordinates corresponding to each cell in the 2D array</li>\n",
    "    <li>the coordinate reference system of the data</li>\n",
    "    <li>the desired coordinate reference system for the resulting plot</li>\n",
    "</ol>\n",
    "\n",
    "<p>Since we used the <code>parse_cf()</code> method earlier, we can use MetPy shortcuts to find items 1-3. We just found item 4 above, and item 5 can be anything we choose!</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. 2D data array\n",
    "data = gfs_ds['Temperature_isobaric'].metpy.sel(vertical = 1000 * units.hPa).squeeze()\n",
    "\n",
    "# 2 and 3. x and y coordinates\n",
    "lon = data.metpy.x\n",
    "lat = data.metpy.y\n",
    "\n",
    "# 4. crs of the data\n",
    "data_crs = ccrs.PlateCarree()\n",
    "\n",
    "# 5. crs of the plot\n",
    "plot_crs = ccrs.LambertConformal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>: \n",
    "\n",
    "What does <code>.squeeze()</code> do? Try testing by examining the difference by running that line of code with and without the use of the method. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put it all together and plot it on our axes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection=plot_crs)\n",
    "\n",
    "# display the data using filled contours, contourf()\n",
    "cntrf = ax.contourf(lon, lat, data, transform=data_crs, cmap='coolwarm')\n",
    "cb = fig.colorbar(cntrf, label='Temperature (K)', extend='both')\n",
    "\n",
    "# set the axes extent in the format [western border, eastern border, southern border, northern border]\n",
    "ax.set_extent([-121, -68, 10, 70], crs=ccrs.PlateCarree())\n",
    "\n",
    "# add Cartopy's built-in coastlines for reference\n",
    "ax.coastlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"calc\"></a>\n",
    "## Preview: Calculations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier this morning your got a preview of how to make calculations using MetPy tools on integer data. Now, we have learned how to access multidimensional data that we've requested from a remote THREDDS Data Server. Let's now combine everything we've done today and get a preview of what's to come tomorrow.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>: Calculating advection of a new variable\n",
    "    \n",
    "Tasks:   \n",
    "<ol>\n",
    "    <li>Request data\n",
    "        <ul>\n",
    "            <li>Using the NetCDF Subset Service, build a query and request your data from a THREDDS Data Server.</li>\n",
    "            <li>For this exercise, the data you use should be the <b>Best GFS Half Degree Forecast Time Series</b>, as was requested above.</li>\n",
    "            <li>You <b>must</b> request the u and v components of wind and at least one other variable that makes reasonable sense to be advected (temperature? specific humidity? check the available variables!).</li>\n",
    "            <li>We recommend requesting variables on <b>isobaric surfaces</b> and within a spatial extent of a single continent to reduce the amount of data required.</li>\n",
    "            <li>Use the xarray <code>NetCDF4DataStore</code> backends to open your netCDF file as an xarray DataSet</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Prepare data\n",
    "        <ul>\n",
    "            <li>Choose a single vertical level to calculate horizontal advection. </li>\n",
    "            <li>Ensure the dimensionality of all variables is <b>2</b>, latitude and longitude only.</li>\n",
    "            <li>At the end of this stage, you should have three 2-dimensional DataArrays the u-component of wind, the v-component of wind, and a third advected variable.</li>\n",
    "        </ul>\n",
    "    </li>    \n",
    "    <li>Calculate advection\n",
    "        <ul>\n",
    "            <li><code>import metpy.calc as mpcalc</code></li>\n",
    "            <li>Use the example provided in the <a href=\"https://unidata.github.io/MetPy/latest/examples/calculations/Advection.html#sphx-glr-examples-calculations-advection-py\" target=\"blank\">Advection reference guide</a> to calculate advection using the <code>advection()</code> function. </li>\n",
    "            <li>Optionally: plot your result using any plotting tool of your choice</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## More Information\n",
    "\n",
    "### Further Practice\n",
    "Project Pythia: Xarray Tutorial: https://foundations.projectpythia.org/core/xarray.html\n",
    "\n",
    "Project Pythia: Cartopy Tutorial: https://foundations.projectpythia.org/core/cartopy.html\n",
    "\n",
    "Project Pythia: Datetime Tutorial: https://foundations.projectpythia.org/core/datetime.html\n",
    "\n",
    "Siphon Examples: https://unidata.github.io/siphon/latest/examples/index.html\n",
    "\n",
    "THREDDS Data Server User Guide: https://docs.unidata.ucar.edu/tds/current/userguide/index.html\n",
    "\n",
    "### Save Your Work\n",
    "<p>To save any of the files you modified or edited in this session:\n",
    "    <ol>\n",
    "        <li>Right click on any item in the left-side navigation pane</li>\n",
    "        <li>Select <b>Download</b></li>\n",
    "    </ol>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    To recreate the Conda environment used for this session on your local computer:\n",
    "<ol>\n",
    "\t<li>\n",
    "\t\tOpen a terminal (Linux or MacOS) or Anaconda Prompt (Windows). <br>\n",
    "\t\tWindows users: If Anaconda Prompt does not exist on your computer, Conda is not installed. Proceed with step 2.2.\n",
    "\t</li>\n",
    "\t<li>\n",
    "\t\tConfirm that Conda is installed by executing: <br>\n",
    "\t\t<b>conda --version</b>\n",
    "\t\t<ol>\n",
    "\t\t\t<li>\n",
    "\t\t\t\tIf Conda is installed, a version number will be returned. Proceed to step 3.\n",
    "\t\t\t</li>\n",
    "\t\t\t<li>\n",
    "\t\t\t\tIf Conda is not installed, proceed with the installation instructions provided for your operating system at <a href=\"https://unidata.github.io/python-training/#installing-conda\" target=\"blank\">this link</a>, then proceed to step 3.\n",
    "\t\t\t</li>\n",
    "\t\t</ol>\n",
    "\t</li>\n",
    "\t<li>\n",
    "\t\tDownload the conda environment used in this workshop. On the link below, Shift + Right Click &gt; Save link as &gt; save the file as environment.yml in a location of your choosing.<br>\n",
    "\t\t<a href=\"https://raw.githubusercontent.com/Unidata/metpy-analysis/main/environment.yml\">https://raw.githubusercontent.com/Unidata/metpy-analysis/main/environment.yml</a>\n",
    "\t</li>\n",
    "\t<li>\n",
    "\t\tIn your terminal or command prompt, change directories to the location where the environment.yml file was saved. \n",
    "\t</li>\n",
    "\t<li>\n",
    "\t\tSet up the course Python environment with the following command. <br>\n",
    "\t\tNote: this will take a few minutes to complete. <br>\n",
    "\t\t<b>conda env create -f environment.yml</b>\n",
    "\t</li>\n",
    "\t<li>\n",
    "\t\tVerify that the environment installed correctly by looking for <b>metpy-analysis</b> in your conda environment list <br>\n",
    "\t\t<b>conda env list</b>\n",
    "\t</li>\n",
    "\t<li>\n",
    "\t\tTo use the new environment, activate the new environment<br>\n",
    "\t\t<b>conda activate metpy-analysis</b>\n",
    "\t</li>\n",
    "\t<li>\n",
    "\t\tLaunch Jupyter Lab<br>\n",
    "\t\t<b>jupyter lab</b>\n",
    "\t</li>\n",
    "</ol>\n",
    "  \n",
    "### Connect with Unidata\n",
    "https://twitter.com/unidata\n",
    "\n",
    "https://twitter.com/metpy\n",
    "\n",
    "https://youtube.com/unidatanews\n",
    "\n",
    "https://www.linkedin.com/company/unidatanews"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metpy-analysis]",
   "language": "python",
   "name": "conda-env-metpy-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
